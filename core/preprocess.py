import tempfile
import time
import geopandas as gpd
import logging
import os
import psutil
import pandas as pd
from pathlib import Path
from osgeo import gdal
from utils.timer import timeit
from utils.geodata_io import read_geodata, write_geodata
from shapely.validation import make_valid
import re

logger = logging.getLogger(__name__)

def normalize_column_name(name):
    """ç»Ÿä¸€å­—æ®µåæ ¼å¼ï¼ˆå°å†™+å»ç‰¹æ®Šå­—ç¬¦ï¼‰"""
    return re.sub(r'[^a-z0-9]', '', name.lower().strip())

def find_column_by_normalized(df, target):
    """é€šè¿‡æ ‡å‡†åŒ–åç§°æŸ¥æ‰¾å­—æ®µ"""
    target_norm = normalize_column_name(target)
    for col in df.columns:
        if normalize_column_name(col) == target_norm:
            return col
    return None

@timeit("é‡æŠ•å½±åˆ° EPSG:4547")
def reproject_to_epsg4547(gdf: gpd.GeoDataFrame,
                          target_crs: str = 'EPSG:4547') -> gpd.GeoDataFrame:
    """
    å°†è¾“å…¥å›¾å±‚æŠ•å½±åˆ° CGCS2000ï¼ˆEPSG:4547ï¼‰
    å‚æ•°:
        gdf (GeoDataFrame): è¾“å…¥å›¾å±‚
        target_crs (str): ç›®æ ‡æŠ•å½±åæ ‡ç³»
    è¿”å›:
        GeoDataFrame: é‡æŠ•å½±åçš„å›¾å±‚
    """
    original_crs = gdf.crs.to_string() if gdf.crs else "æœªå®šä¹‰"
    logger.info(f"ğŸ“ åŸå§‹åæ ‡ç³»ï¼š{original_crs}")

    if gdf.crs is None:
        logger.warning("âš ï¸ æ£€æµ‹åˆ°æœªå®šä¹‰CRSï¼Œå¼ºåˆ¶æŒ‡å®šä¸ºEPSG:4326")
        gdf = gdf.set_crs("EPSG:4326", allow_override=True)

    # æ‰§è¡Œé‡æŠ•å½±
    gdf = gdf.to_crs(target_crs)
    logger.info(f"âœ… é‡æŠ•å½±å®Œæˆ ï¼ˆç›®æ ‡CRS: {gdf.crs}ï¼‰")
    return gdf

@timeit("æ ‡å‡†åŒ–å­—æ®µç»“æ„")
def standardize_fields(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
    """
    æ ‡å‡†åŒ–å­—æ®µå‘½åï¼Œç»Ÿä¸€ä¸ºç®—æ³•æ‰€éœ€å­—æ®µ
    - GRIDCODE â†’ land_code
    - Landuse â†’ land_name
    - ID â†’ poly_id
    å¹¶å»é™¤å¤šä½™å­—æ®µ
    """
    # åˆ é™¤QGISä¿®å¤ç”Ÿæˆçš„ä¸´æ—¶å­—æ®µ
    redundant_fields = ["_errors", "layer", "path"]
    gdf = gdf.drop(columns=redundant_fields, errors="ignore")

    # å¼¹æ€§å­—æ®µæ˜ å°„ï¼ˆæ”¯æŒå¤§å°å†™å˜ä½“ï¼‰
    field_mapping = {
        'GRIDCODE': 'land_code',
        'Landuse': 'land_name',
        'ID': 'poly_id'
    }

    # æŸ¥æ‰¾å®é™…å­˜åœ¨çš„å­—æ®µï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    actual_fields = {col.upper(): col for col in gdf.columns}
    mapped_fields = {}

    for expected, new_name in field_mapping.items():
        found_col = find_column_by_normalized(gdf, expected)
        if found_col:
            mapped_fields[found_col] = new_name
        else:
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°å­—æ®µ '{expected}'ï¼Œä½¿ç”¨é»˜è®¤å€¼åˆå§‹åŒ–")
            gdf[new_name] = 0  # åˆå§‹åŒ–é»˜è®¤å€¼

    # æ‰§è¡Œå­—æ®µé‡å‘½å
    if mapped_fields:
        gdf = gdf.rename(columns=mapped_fields)

    # å¼ºåˆ¶è½¬æ¢ land_code ä¸ºæ•´æ•°
    if 'land_code' in gdf.columns:
        gdf['land_code'] = gdf['land_code'].astype(int)

    # åˆ é™¤éæ ¸å¿ƒå­—æ®µï¼ˆä¿ç•™geometryï¼‰
    core_fields = {'poly_id', 'land_code', 'land_name', 'geometry'}
    extra_fields = [col for col in gdf.columns if col not in core_fields]

    if extra_fields:
        logger.info(f"ğŸ—‘ï¸ ç§»é™¤å†—ä½™å­—æ®µ: {', '.join(extra_fields)}")
        gdf = gpd.GeoDataFrame(
            gdf[list(core_fields)],
            crs=gdf.crs
        )

    # å‡ ä½•ç±»å‹éªŒè¯ï¼ˆæ”¯æŒå¤šå‡ ä½•ç±»å‹ï¼‰
    if gdf.geometry.type.isin(['GeometryCollection']).any():
        logger.warning("âš ï¸ æ£€æµ‹åˆ°æ··åˆå‡ ä½•ç±»å‹ï¼Œå°è¯•æå–å¤šè¾¹å½¢")
        gdf = gdf.explode(index_parts=True)
        gdf = gdf[gdf.geometry.type.isin(['Polygon', 'MultiPolygon'])]

    if gdf.crs != 'EPSG:4547':
        logger.warning(f"âš ï¸ æ£€æµ‹åˆ°éæ ‡å‡†CRS: {gdf.crs}ï¼Œé‡æ–°æŠ•å½±åˆ°EPSG:4547")
        gdf = gdf.to_crs('EPSG:4547')

    return gdf

@timeit("æ‹“æ‰‘æ ¡éªŒä¸ä¿®å¤")
def validate_topology(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
    """
    æ‰§è¡Œæ‹“æ‰‘æ ¡éªŒï¼š
    1. ä¿®å¤æ— æ•ˆå‡ ä½•
    2. ç§»é™¤ç©ºå‡ ä½•
    3. ç¡®ä¿å¤šè¾¹å½¢å°é—­æ€§
    """
    # åŸºç¡€åˆ†å—å¤§å°
    base_chunk_size = 500

    # å†…å­˜æ£€æµ‹ä¸åŠ¨æ€è°ƒæ•´
    mem = psutil.virtual_memory()
    avail_gb = mem.available / (1024 ** 3)

    if avail_gb < 1.0:  # å†…å­˜å±æ€¥ (<1GB)
        chunk_size = 100
        logger.critical(f"âš ï¸ å†…å­˜å±æ€¥! å¯ç”¨: {avail_gb:.2f}GB â†’ åˆ†å—é™è‡³: {chunk_size}")
    elif avail_gb < 2.0:  # å†…å­˜ä¸è¶³ (<2GB)
        chunk_size = 200
        logger.warning(f"âš ï¸ å†…å­˜ä¸è¶³! å¯ç”¨: {avail_gb:.2f}GB â†’ åˆ†å—é™è‡³: {chunk_size}")
    else:  # å†…å­˜å……è¶³
        chunk_size = base_chunk_size
        logger.info(f"â™»ï¸ å†…å­˜å……è¶³: {avail_gb:.2f}GB â†’ ä½¿ç”¨æ ‡å‡†åˆ†å—: {chunk_size}")

    # æ£€æµ‹æ— æ•ˆå‡ ä½•
    invalid_idx = ~gdf.geometry.is_valid
    invalid_count = invalid_idx.sum()
    if not invalid_count:
        return gdf

    logger.warning(f"âš ï¸ å‘ç°{invalid_count}ä¸ªæ— æ•ˆå‡ ä½•ï¼Œå¯åŠ¨å®‰å…¨ä¿®å¤...")

    # æ˜¾å¼è®¾ç½®GDALå¼‚å¸¸æ¨¡å¼
    gdal.DontUseExceptions()

    # åˆ†å—ä¿®å¤ + æ˜¾å¼èµ„æºé‡Šæ”¾
    chunk_size = 500  # è¿›ä¸€æ­¥å‡å°åˆ†å—è§„æ¨¡
    repaired_geoms = []  # å­˜å‚¨ä¿®å¤åçš„å‡ ä½•

    for i in range(0, invalid_count, chunk_size):
        chunk = gdf[invalid_idx].iloc[i:i + chunk_size].copy()
        try:
            # ç‹¬ç«‹ä¸´æ—¶æ–‡ä»¶è·¯å¾„
            tmp_path = os.path.join(tempfile.gettempdir(), f"gdal_fix_{os.getpid()}_{time.time_ns()}.gpkg" )
            chunk.to_file(tmp_path, driver="GPKG")

            # å¼ºåˆ¶å…³é—­GDALæ•°æ®é›†é‡Šæ”¾èµ„æº
            ds = gdal.OpenEx(tmp_path, gdal.OF_VECTOR | gdal.OF_UPDATE)
            layer = ds.GetLayer()
            gdal.VectorTranslate(
                tmp_path, tmp_path,
                accessMode="update",
                layerName=layer.GetName(),
                makeValid=True
            )
            ds = None  # æ˜¾å¼é‡Šæ”¾GDALèµ„æº

            # è¯»å–ä¿®å¤ç»“æœ
            repaired = gpd.read_file(tmp_path)
            repaired_geoms.extend(repaired.geometry.tolist())
        except Exception as e:
            logger.error(f"âŒ åˆ†å—{i}-{i + chunk_size}ä¿®å¤å¤±è´¥ï¼Œå›é€€ç¼“å†²ä¿®å¤: {str(e)}")
            repaired_geoms.extend(chunk.geometry.buffer(0).tolist())
        finally:
            # åŒé‡å®‰å…¨åˆ é™¤
            if os.path.exists(tmp_path):
                try:
                    os.unlink(tmp_path)  # ç«‹å³åˆ é™¤
                except Exception as e:
                    logger.error(f"âŒ ä¸´æ—¶æ–‡ä»¶åˆ é™¤å¤±è´¥: {tmp_path} | é”™è¯¯: {str(e)}")

    # åˆå¹¶ä¿®å¤ç»“æœ
    gdf.loc[invalid_idx, "geometry"] = repaired_geoms
    return gdf

@timeit("é¢„å¤„ç†æµæ°´çº¿")
def preprocess_shapefile(input_path: str, output_path: str) -> None:
    """
    çŸ¢é‡æ•°æ®é¢„å¤„ç†

    1. æ”¯æŒGeoPackageå›¾å±‚è·¯å¾„æ ¼å¼
    2. è‡ªåŠ¨ä¿®å¤å‡ ä½•é”™è¯¯
    3. åŠ¨æ€å­—æ®µæ ‡å‡†åŒ–
    4. å¼ºåˆ¶æŠ•å½±åˆ°EPSG:4547

    å‚æ•°:
        input_path: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒ"path.gpkg|layername=xxx"æ ¼å¼ï¼‰
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    logger.info(f"ğŸ“¥ åŠ è½½æºæ•°æ®: {input_path}")

    # ç›´æ¥ä¼ é€’è·¯å¾„åˆ°read_geodataï¼Œä¸è½¬æ¢Pathå¯¹è±¡
    gdf = read_geodata(input_path)

    logger.info(f"âœ… åŠ è½½æˆåŠŸ â†’ è¦ç´ æ•°: {len(gdf)} | CRS: {gdf.crs}")

    # æ‰§è¡Œå¤„ç†æµæ°´çº¿
    try:
        gdf = standardize_fields(gdf)

        # è·³è¿‡å‡ ä½•ä¿®å¤ï¼ˆå·²åœ¨QGISå®Œæˆï¼‰
        # gdf = validate_topology(gdf)

        if gdf.crs != 'EPSG:4547':
            logger.info(f"ğŸ”„ åæ ‡ç³»è½¬æ¢: {gdf.crs} â†’ EPSG:4547")
            gdf = gdf.to_crs('EPSG:4547')

    except Exception as e:
        logger.error(f"âŒ é¢„å¤„ç†å¤±è´¥: {str(e)}")
        raise

    # ä¿å­˜ç»“æœ
    write_geodata(gdf, output_path)
    logger.info(f"ğŸ’¾ ä¿å­˜é¢„å¤„ç†ç»“æœ: {output_path}")